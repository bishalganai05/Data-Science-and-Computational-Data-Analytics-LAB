{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvlz5OP0OTiP"
      },
      "outputs": [],
      "source": [
        "# i. K-Means:\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "# Load and preprocess data\n",
        "X = load_data()\n",
        "# Assuming you have a dataset with multiple features\n",
        "# Choose the number of clusters (k)\n",
        "k = 3\n",
        "# Create and fit a K-Means model\n",
        "model = KMeans(n_clusters=k)\n",
        "model.fit(X)\n",
        "# Get cluster labels and centroids\n",
        "cluster_labels = model.labels_\n",
        "centroids = model.cluster_centers_\n",
        "# Visualize the clusters\n",
        "plt.scatter(X[:, 0], X[:, 1], c=cluster_labels)\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1, c='red', marker='x')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ii) Hierarchical Clustering:\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "import matplotlib.pyplot as plt\n",
        "# Load and preprocess data\n",
        "X = load_data()\n",
        "# Perform hierarchical clustering\n",
        "linkage_matrix = linkage(X, method='ward') # Choose the linkage method\n",
        "# Create a dendrogram to visualize the hierarchy\n",
        "dendrogram(linkage_matrix, orientation='top')\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "upmnshBDOYc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iii) DBSCAN (Density-Based Spatial Clustering of Applications with Noise):\n",
        "from sklearn.cluster import DBSCAN\n",
        "# Load and preprocess data\n",
        "X = load_data()\n",
        "# Create and fit a DBSCAN model\n",
        "model = DBSCAN(eps=0.5, min_samples=5) # Set parameters as needed\n",
        "model.fit(X)\n",
        "# Get cluster labels\n",
        "cluster_labels = model.labels_"
      ],
      "metadata": {
        "id": "sKfUMdQFObN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iv) Dimensionality Reduction: Principal Component Analysis (PCA):\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Load and preprocess data\n",
        "X = load_data()\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "# Build a simple autoencoder model\n",
        "model = tf.keras.Sequential([\n",
        "tf.keras.layers.Input(shape=(X.shape[1],)), tf.keras.layers.Dense(64, activation='relu'), tf.keras.layers.Dense(32, activation='relu'), tf.keras.layers.Dense(16, activation='relu'), tf.keras.layers.Dense(32, activation='relu'), tf.keras.layers.Dense(64, activation='relu'), tf.keras.layers.Dense(X.shape[1])\n",
        "])\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X, X, epochs=10, batch_size=32)\n",
        "# Encode data using the middle layer\n",
        "encoded_data = model.layers[2](X)"
      ],
      "metadata": {
        "id": "AOlFRlmBOdCi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}